{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from nltk.util import ngrams \n",
    "import emoji\n",
    "from itertools import chain\n",
    "paths = \"./dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_two_three(selects):\n",
    "    global All_selects\n",
    "    thgrams_selects = {}\n",
    "    bigrams_selects = {}\n",
    "    selects_token ={}\n",
    "    for select in selects:\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        tokens = tokenizer.tokenize(select)\n",
    "        tokens = [i for i in tokens if(i.lower() not in stopwords.words('english'))]\n",
    "        bigrams_t = ngrams(tokens, 2) \n",
    "        thgrams_t = ngrams(tokens, 3)\n",
    "        tokens = list(set(tokens))\n",
    "        bigrams_t = list(set(bigrams_t))\n",
    "        thgrams_t = list(set(thgrams_t))\n",
    "        for t in thgrams_t:\n",
    "            t = str(t).split(\"'\")\n",
    "            t = t[1] +\" \"+ t[3]+\" \"+t[5]\n",
    "            if t not in thgrams_selects:\n",
    "                thgrams_selects[t] = 1\n",
    "            else:\n",
    "                thgrams_selects[t] += 1\n",
    "        for b in bigrams_t:\n",
    "            b = str(b).split(\"'\")\n",
    "            b = b[1]+\" \"+b[3]\n",
    "            if b not in bigrams_selects:\n",
    "                bigrams_selects[b] = 1\n",
    "            else:\n",
    "                bigrams_selects[b] += 1\n",
    "        for token in tokens:\n",
    "            if token not in selects_token:\n",
    "                selects_token[token] = 1\n",
    "            else:\n",
    "                selects_token[token] += 1\n",
    "    df_selects_token = pd.DataFrame.from_dict(selects_token,orient=\"index\",columns=[\"频率\"]).sort_values(by=\"频率\",ascending=False)\n",
    "    df_selects_token = df_selects_token[df_selects_token[\"频率\"]>=3]\n",
    "    df_bigrams_selects = pd.DataFrame.from_dict(bigrams_selects,orient=\"index\",columns=[\"频率\"]).sort_values(by=\"频率\",ascending=False)\n",
    "    df_bigrams_selects = df_bigrams_selects[df_bigrams_selects[\"频率\"]>=2]\n",
    "    df_thgrams_selects = pd.DataFrame.from_dict(thgrams_selects,orient=\"index\",columns=[\"频率\"]).sort_values(by=\"频率\",ascending=False)\n",
    "    df_thgrams_selects = df_thgrams_selects[df_thgrams_selects[\"频率\"]>=2]\n",
    "    return df_selects_token,df_bigrams_selects,df_thgrams_selects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_out(titles,comments):\n",
    "    df_titles_token,df_bigrams_titles,df_thgrams_titles = get_one_two_three(titles)\n",
    "    df_comments_token,df_bigrams_comments,df_thgrams_comments = get_one_two_three(comments)\n",
    "    df_titles_token['标题-1字']=df_titles_token.index\n",
    "    df_titles_token = df_titles_token.reset_index(drop=True)\n",
    "    df_bigrams_titles['标题-2字']=df_bigrams_titles.index\n",
    "    df_bigrams_titles = df_bigrams_titles.reset_index(drop=True)\n",
    "    df_thgrams_titles['标题-3字']=df_thgrams_titles.index\n",
    "    df_thgrams_titles = df_thgrams_titles.reset_index(drop=True)\n",
    "    df_comments_token['评论-1字']=df_comments_token.index\n",
    "    df_comments_token = df_comments_token.reset_index(drop=True)\n",
    "    df_bigrams_comments['评论-2字']=df_bigrams_comments.index\n",
    "    df_bigrams_comments = df_bigrams_comments.reset_index(drop=True)\n",
    "    df_thgrams_comments['评论-3字']=df_thgrams_comments.index\n",
    "    df_thgrams_comments = df_thgrams_comments.reset_index(drop=True)\n",
    "    if df_titles_token.empty:\n",
    "        df_t = pd.DataFrame()\n",
    "    elif df_bigrams_titles.empty:\n",
    "        df_t = df_titles_token\n",
    "    elif df_thgrams_titles.empty:\n",
    "        df_t = pd.concat([df_titles_token,df_bigrams_titles],axis=1)\n",
    "    else:\n",
    "        df_t = pd.concat([df_titles_token,df_bigrams_titles,df_thgrams_titles],axis=1)\n",
    "    if df_thgrams_comments.empty:\n",
    "        df_c = pd.concat([df_comments_token,df_bigrams_comments],axis=1)\n",
    "    else:\n",
    "        df_c = pd.concat([df_comments_token,df_bigrams_comments,df_thgrams_comments],axis=1)\n",
    "    df_out = pd.concat([df_t,df_c],axis=1)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_coloum(df):\n",
    "    df.columns = [x+\"-\"+str(i) if x==\"频率\" else x for i,x in enumerate(df.columns)]\n",
    "    a,b,c = [],[],[]\n",
    "    for i,j in enumerate(list(df.columns)):\n",
    "        if i%2==0:\n",
    "            a.append(j)\n",
    "        else:\n",
    "            b.append(j)\n",
    "    for i in range(int(len(list(df.columns))/2)):\n",
    "        c.append(b[i])\n",
    "        c.append(a[i])\n",
    "    df = df[c]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B074737RWR-US-Reviews-200930.xlsx', 'B07474J9BX-US-Reviews-200930.xlsx', 'B07DC7FVND-US-Reviews-200930.xlsx', 'B07GM4TBQC-US-Reviews-200930.xlsx', 'B07MDLFKRW-US-Reviews-200930.xlsx', 'B07PGF62GC-US-Reviews-200930.xlsx', 'B07QH7LFK1-US-Reviews-200930.xlsx', 'B07SZC274F-US-Reviews-200930.xlsx', 'B07TC3L44B-US-Reviews-200930.xlsx', 'B07WZLPCLQ-US-Reviews-200930.xlsx', 'B082WR58HY-US-Reviews-200930.xlsx']\n"
     ]
    }
   ],
   "source": [
    "df_tmp = pd.DataFrame()\n",
    "for _,_,files in os.walk(paths):\n",
    "    print(files)\n",
    "writer = pd.ExcelWriter(\"final.xlsx\")\n",
    "all_titles = []\n",
    "all_comments = []\n",
    "for file in files:\n",
    "    keyname = file.split(\"-\")[0]\n",
    "    path = paths+file\n",
    "    df = pd.read_excel(path)\n",
    "    df = df[[\"标题\",\"内容\"]]\n",
    "    titles = []\n",
    "    comments = []\n",
    "    df.标题.apply(lambda x:titles.append(x))\n",
    "    df.内容.apply(lambda x:comments.append(x))\n",
    "    titles = [emoji.demojize(str(i)).lower() for i in titles]\n",
    "    comments = [emoji.demojize(str(i)).lower() for i in comments]\n",
    "    all_titles.append(titles)\n",
    "    all_comments.append(comments)\n",
    "    df_out = get_df_out(titles,comments)\n",
    "    df_out = change_coloum(df_out)\n",
    "    df_out.to_excel(writer,sheet_name=keyname+\"-\"+str(len(df)),index=None)\n",
    "df_out = get_df_out(list(chain.from_iterable(all_titles)),list(chain.from_iterable(all_comments)))\n",
    "df_out = change_coloum(df_out)\n",
    "df_out.to_excel(\"all_titles_comments.xlsx\",sheet_name=\"所有标题和评论词频汇总\",index=None)\n",
    "#     print(df_out.columns)\n",
    "writer.close()\n",
    "test = pd.read_excel(\"final.xlsx\",None)\n",
    "writer = pd.ExcelWriter(\"final-out.xlsx\")\n",
    "for key in test.keys():\n",
    "    pd_out = test[key]\n",
    "    pd_out = pd_out.head(100)\n",
    "    pd_out.to_excel(writer,sheet_name=key,index=None)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
