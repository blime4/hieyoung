{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from contextlib import closing\n",
    "import threading\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageEnhance\n",
    "import xlsxwriter\n",
    "import xlrd\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "key_words = [\"plant hanger\"]\n",
    "# key_words = []\n",
    "bad_words = [\"augmented reality\",\"reversible\",\"system\",\"method\",\"tool\",\"process\",\"indicator\",\"technique\",\"saucer\"]\n",
    "time_sacle = \"60\"\n",
    "failurls = []\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36\"\n",
    "}\n",
    "\n",
    "url = \"http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=page_change&u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&r=0&f=S&l=50&TERM1=search_change&FIELD1=&co1=AND&TERM2=&FIELD2=&d=PTXT\"\n",
    "\n",
    "\n",
    "root = Tk()\n",
    "root.geometry('850x550')\n",
    "root.title(\"专利查询和搜索\")\n",
    "\n",
    "key_frame = Frame(width=350,height=300,bg=\"LightPink\")\n",
    "bad_frame = Frame(width=350,height=300,bg=\"Thistle\")\n",
    "fun_frame = Frame(width=700,height=50,bg=\"LightSeaGreen\")\n",
    "out_frame = Frame(width=700,height=250,bg=\"green\")\n",
    "\n",
    "out_frame_Labelframe = LabelFrame(out_frame,width=700,height=200,text=\"输出信息\",padx=10,pady=10)\n",
    "out_frame_Text = Text(out_frame_Labelframe,width=100,height=10)\n",
    "\n",
    "def showinfo(result):\n",
    "    realtime = time.strftime(\"%Y-%m-%d %H:%M:%S \")\n",
    "    textvar = realtime + result #系统时间和传入结果\n",
    "    out_frame_Text.insert(END,textvar) #显示在text框里面\n",
    "    out_frame_Text.insert(INSERT,'\\n') #换行\n",
    "    out_frame_Text.update()\n",
    "\n",
    "out_frame_Text.grid()\n",
    "out_frame_Labelframe.grid()\n",
    "# key_word_Scrollbar = Scrollbar(key_frame).grid(rowspan=3,column)\n",
    "key_word_Var = StringVar()\n",
    "key_word_Var.set(\"填写关键词\")\n",
    "key_word_Entry = Entry(key_frame,width=30,textvariable=key_word_Var)\n",
    "def key_word_Entry_bind(event):\n",
    "    key_word_Fun(key_word_Var.get())\n",
    "key_word_Entry.bind(\"<Return>\", key_word_Entry_bind)\n",
    "key_word_Entry.grid(row=0,column=0)\n",
    "def key_word_Fun(key_word_var_):\n",
    "    global key_words\n",
    "    if key_word_var_ == \"\":\n",
    "        pass\n",
    "    elif key_word_var_ == \"填写关键词\":\n",
    "        pass\n",
    "    else:\n",
    "        if key_word_var_ in key_words:\n",
    "            pass\n",
    "        else:\n",
    "            key_words.append(str(key_word_var_))\n",
    "            key_word_Listbox.delete(0,END)\n",
    "            for key_word in key_words:\n",
    "                key_word_Listbox.insert(END,key_word)\n",
    "                \n",
    "key_word_Button = Button(key_frame,text=\"添加\",command=lambda:key_word_Fun(key_word_Var.get())).grid(row=0,column=1)\n",
    "key_word_Listbox = Listbox(key_frame,selectmode=MULTIPLE,height=10,width=60)\n",
    "# key_word_Listbox = Listbox(key_frame,selectmode=MULTIPLE,height=10,width=60,yscrollcommand=key_word_Scrollbar.set)\n",
    "for key_word in key_words:\n",
    "    key_word_Listbox.insert(END,key_word)\n",
    "key_word_Listbox.grid(row=1,columnspan=2)\n",
    "# key_word_Scrollbar.config(command=key_word_Listbox.yview)\n",
    "def key_word_Listbox_delete(ACTIVE):\n",
    "    global key_words\n",
    "#     showinfo(int(key_word_Listbox.curselection()[0]))\n",
    "    key_words = [j for i,j in enumerate(key_words) if i != int(key_word_Listbox.curselection()[0])]\n",
    "    key_word_Listbox.delete(ACTIVE)\n",
    "    key_word_Listbox.delete(0,END)\n",
    "    for key_word in key_words:\n",
    "        key_word_Listbox.insert(END,key_word)\n",
    "key_word_Listbox_Button = Button(key_frame,text=\"删除关键词\",command=lambda:key_word_Listbox_delete(ACTIVE)).grid(row=2,columnspan=2)\n",
    "\n",
    "\n",
    "\n",
    "bad_word_Var = StringVar()\n",
    "bad_word_Var.set(\"填写排除词\")\n",
    "bad_word_Entry = Entry(bad_frame,width=50,textvariable=bad_word_Var)\n",
    "def bad_word_Entry_bind(event):\n",
    "    bad_word_Fun(key_word_Var.get())\n",
    "bad_word_Entry.bind(\"<Return>\", key_word_Entry_bind)\n",
    "bad_word_Entry.grid(row=0,column=0)\n",
    "def bad_word_Fun(bad_word_var_):\n",
    "    global bad_words\n",
    "    if bad_word_var_ == \"\":\n",
    "        pass\n",
    "    elif bad_word_var_ == \"填写排除词\":\n",
    "        pass\n",
    "    else:\n",
    "        if bad_word_var_ in bad_words:\n",
    "            pass\n",
    "        else:\n",
    "            bad_words.append(str(bad_word_var_))\n",
    "            bad_word_Listbox.delete(0,END)\n",
    "            for bad_word in bad_words:\n",
    "                bad_word_Listbox.insert(END,bad_word)\n",
    "                \n",
    "bad_word_Button = Button(bad_frame,text=\"添加\",command=lambda:bad_word_Fun(bad_word_Var.get())).grid(row=0,column=1)\n",
    "bad_word_Listbox = Listbox(bad_frame,selectmode=MULTIPLE,height=10,width=60)\n",
    "for bad_word in bad_words:\n",
    "    bad_word_Listbox.insert(END,bad_word)\n",
    "bad_word_Listbox.grid(row=1,columnspan=2)\n",
    "\n",
    "def bad_word_Listbox_delete(ACTIVE):\n",
    "    global bad_words\n",
    "#     showinfo(int(bad_word_Listbox.curselection()[0]))\n",
    "    bad_words = [j for i,j in enumerate(bad_words) if i != int(bad_word_Listbox.curselection()[0])]\n",
    "    bad_word_Listbox.delete(ACTIVE)\n",
    "    bad_word_Listbox.delete(0,END)\n",
    "    for bad_word in bad_words:\n",
    "        bad_word_Listbox.insert(END,bad_word)\n",
    "bad_word_Listbox_Button = Button(bad_frame,text=\"删除排除词\",command=lambda:bad_word_Listbox_delete(ACTIVE)).grid(row=2,columnspan=2)\n",
    "\n",
    "time_scale_var = StringVar()\n",
    "time_scale_var.set(\"60\")\n",
    "def get_time_scale_var():\n",
    "    global time_sacle\n",
    "    time_sacle = str(time_scale_var.get())\n",
    "fun_frame_Label = Label(fun_frame,text=\"爬取时间间隔设置: 秒\").grid(row=0,column=0)\n",
    "fun_frame_Spinbox = Spinbox(fun_frame,from_=1,to=100,increment=1,textvariable=time_scale_var,command=get_time_scale_var).grid(row=0,column=1)\n",
    "# fun_frame_Scale = Scale(fun_frame,from_=1,to=100,resolution=1,orient=HORIZONTAL,variable=time_scale_var,command=get_time_scale_var).grid(row=0,column=1)\n",
    "\n",
    "#开始爬取数据\n",
    "def spider():\n",
    "    showinfo(\"[ run ]---开始爬取数据\")\n",
    "    showinfo(\"[ tip ]---这一步需要的时间，和爬取的时间间隔和爬取的内容数量有关，请耐心等待。\")\n",
    "    global key_words\n",
    "    global time_sacle\n",
    "    spider_key_words = key_words\n",
    "    for key_word in spider_key_words:\n",
    "        page_a = []\n",
    "        page_img = []\n",
    "        page_href = []\n",
    "        key_words_url = url\n",
    "        key_words_url = key_words_url.replace(\"search_change\",str(key_word))\n",
    "        url_1 = key_words_url\n",
    "        url_1 = url_1.replace(\"page_change\",\"1\")\n",
    "        response = requests.get( url_1 , headers=headers )\n",
    "        if response.status_code == 200:\n",
    "            showinfo(\"[一切正常]---开始爬取 \"+key_word)\n",
    "        else:\n",
    "            showinfo(\"[出错]---错误状态码：\"+response.status_code)\n",
    "        html_doc = response.text\n",
    "        response.close()\n",
    "        soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "        total_len = soup.find(\"body\").find_all(\"i\")[1].find_all(\"strong\")[2].get_text()\n",
    "        page_num = int(float(total_len)/50.5)+2\n",
    "        showinfo(\"一共\"+total_len+\"个论文，共\"+str(page_num-1)+\"页\")\n",
    "        soup_tb = soup.find_all(\"table\")\n",
    "        for tb in soup_tb:\n",
    "            for tr in tb.find_all(\"tr\"):\n",
    "                valign_top = list(tr.find_all(\"td\",attrs={\"valign\":\"top\"}))\n",
    "                if len(valign_top)>=2:\n",
    "                    num = valign_top[1].get_text().replace(\",\",\"\")\n",
    "                    img = \"https://pdfpiw.uspto.gov/.piw?Docid=\"+str(num)\n",
    "                    top = valign_top[2]\n",
    "                    href = \"http://patft.uspto.gov/\"+str(top.a.get(\"href\"))\n",
    "                    a = top.get_text()\n",
    "                    a = a.replace(\"\\n\",\" \")\n",
    "                    page_a.append(a)\n",
    "                    page_img.append(img)\n",
    "                    page_href.append(href)\n",
    "        time.sleep(int(time_sacle))\n",
    "        if page_num >= 2:\n",
    "            for i in range(2,page_num):\n",
    "                url_i = key_words_url\n",
    "                url_i = url_i.replace(\"page_change\",str(i))\n",
    "                response = requests.get( url_i , headers=headers )\n",
    "                if response.status_code == 200:\n",
    "                    showinfo(\"[一切正常]---爬取到第\"+str(i)+\"页\")\n",
    "                else:\n",
    "                    showinfo(\"[出错]---错误状态码：\"+response.status_code)\n",
    "                html_doc = response.text\n",
    "                response.close()\n",
    "                soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "                soup_tb = soup.find_all(\"table\")\n",
    "                for tb in soup_tb:\n",
    "                    for tr in tb.find_all(\"tr\"):\n",
    "                        valign_top = list(tr.find_all(\"td\",attrs={\"valign\":\"top\"}))\n",
    "                        if len(valign_top)>=2:\n",
    "                            num = valign_top[1].get_text().replace(\",\",\"\")\n",
    "                            img = \"https://pdfpiw.uspto.gov/.piw?Docid=\"+str(num)\n",
    "                            top = valign_top[2]\n",
    "                            href = \"http://patft.uspto.gov/\"+str(top.a.get(\"href\"))\n",
    "                            a = top.get_text()\n",
    "                            a = a.replace(\"\\n\",\" \")\n",
    "                            page_a.append(a)\n",
    "                            page_img.append(img)\n",
    "                            page_href.append(href)\n",
    "                time.sleep(int(time_sacle))\n",
    "        page_dict = {\"标题\":page_a,\"专利链接\":page_href,\"图片链接\":page_img}\n",
    "        page_df = pd.DataFrame(page_dict)\n",
    "        if not os.path.exists(\"raw_data\"):\n",
    "            os.mkdir(\"raw_data\")\n",
    "        page_df.to_excel(\"./raw_data/\"+key_word+\".xlsx\",index=None)\n",
    "        showinfo(\"[ ok ]---\"+key_word)\n",
    "    showinfo(\"[ ok ]---全部导出完毕，保存在raw_data文件夹中\")\n",
    "\n",
    "\n",
    "\n",
    "# 清洗源数据\n",
    "def clean():\n",
    "    def data_deal(df):\n",
    "        def title_change(title):\n",
    "            if title[0] == \" \":\n",
    "                title = title[1:]\n",
    "            title = title.lower()\n",
    "            return title\n",
    "        def img_change(img):\n",
    "            a = img.split(\"=\")[1]\n",
    "            if a[0] == \"D\":\n",
    "                a = a[0] + \"0\" + a[1:]\n",
    "            elif a[:2] == \"PP\":\n",
    "                a = a[:2] + \"0\" + a[2:]\n",
    "            else:\n",
    "                while(1):\n",
    "                    if len(a)>=8:\n",
    "                        break\n",
    "                    a = \"0\"+a\n",
    "            return \"https://pdfpiw.uspto.gov/.piw?Docid=\"+a\n",
    "        def down_url(img):\n",
    "            a = img.split(\"=\")[1]\n",
    "            one = a[-2:]\n",
    "            two = a[-5:-2]\n",
    "            three = a[-8:-5]\n",
    "            return \"https://pdfpiw.uspto.gov/\"+one+\"/\"+two+\"/\"+three+\"/1.pdf\"\n",
    "        def patent(img):\n",
    "            a = img.split(\"=\")[1]\n",
    "            return a\n",
    "        df[\"专利号\"] = df.apply(lambda row:patent(row[\"图片链接\"]),axis=1)\n",
    "        df[\"标题\"] = df.apply(lambda row:title_change(row[\"标题\"]),axis=1)\n",
    "        df[\"图片链接\"] = df.apply(lambda row:img_change(row[\"图片链接\"]),axis=1)\n",
    "        df[\"pdf下载链接\"] = df.apply(lambda row:down_url(row[\"图片链接\"]),axis=1)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    path = \"./raw_data/\"\n",
    "    if not os.path.exists(path):\n",
    "        showinfo(\"[ error ]---源数据未获取\")\n",
    "    else:\n",
    "        files = os.listdir(path)\n",
    "        if len(files) == 0:\n",
    "            showinfo(\"[ error ]---源数据为空\" )\n",
    "        else:\n",
    "            if not os.path.exists(\"cleaned\"):\n",
    "                os.mkdir(\"cleaned\")\n",
    "            writer = pd.ExcelWriter(\"./cleaned/cleaned_data.xlsx\")    \n",
    "            for file in files:\n",
    "                df = pd.read_excel(path+file)\n",
    "                key = file.split(\".\")[0]\n",
    "                df = data_deal(df)\n",
    "                df.to_excel(writer,sheet_name=key,index=None)\n",
    "            showinfo(\"[ ok ]---数据清洗完成，已保存到cleaned文件夹中\")\n",
    "            writer.close()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#深度清洗源数据\n",
    "def clean_deep():\n",
    "    showinfo(\"[ run ]---正在进行深度清洗源数据\")\n",
    "    if not os.path.exists(\"cleaned\"):\n",
    "        showinfo(\"[ warning ]---数据未清洗，尝试自动清洗\")\n",
    "        clean()\n",
    "    if not os.path.exists(\"cleaned\") or len(os.listdir(\"cleaned\"))==0:\n",
    "        showinfo(\"[ error ]---自动清洗失败\")\n",
    "    else:\n",
    "        try:\n",
    "            df = pd.read_excel(\"./cleaned/cleaned_data.xlsx\",None)\n",
    "            keys = list(df.keys())\n",
    "            df_all = pd.DataFrame()\n",
    "            for i in keys:\n",
    "                df_i = df[i]\n",
    "                df_all = pd.concat([df_i,df_all])\n",
    "            global key_words,bad_words\n",
    "            Hit = [i.lower() for i in key_words]\n",
    "            df_rest = df_all\n",
    "    #         def get_hit(Hit):\n",
    "            df_hit = pd.DataFrame()\n",
    "    #             global df_rest\n",
    "            for i in Hit:\n",
    "                df_hit_i = df_rest[df_rest[\"标题\"].str.contains(i)]\n",
    "                df_rest = df_rest[~df_rest[\"标题\"].str.contains(i)]\n",
    "                df_hit = pd.concat([df_hit,df_hit_i])\n",
    "    #             return df_hit\n",
    "    #         df_hit = get_hit(Hit)\n",
    "    #         def deal_hit(df_hit):\n",
    "            for i in bad_words:\n",
    "                i = i.lower()\n",
    "                df_hit = df_hit[~df_hit[\"标题\"].str.contains(i)]\n",
    "    #             return df_hit\n",
    "    #         df_hit = deal_hit(df_hit)\n",
    "            df_hit.drop_duplicates(subset=[\"专利号\"],keep=\"first\",inplace=True)\n",
    "    #         df_hit[\"标题长度\"] = df_hit.apply(lambda row:len(row[\"标题\"]),axis=1)\n",
    "    #         df_hit.sort_values(by=\"标题长度\",inplace=True)\n",
    "            df_hit = df_hit[[\"专利号\",\"pdf下载链接\"]]\n",
    "            df_hit.to_excel(\"./cleaned/demo.xlsx\",index=None)\n",
    "            df_all.to_excel(\"./cleaned/df_all.xlsx\",index=None)\n",
    "            df_rest.to_excel(\"./cleaned/df_rest.xlsx\",index=None)\n",
    "            showinfo(\"[ ok ]---深度数据清洗完成，已保存到cleaned文件夹demo.xlsx中\")\n",
    "        except:\n",
    "            showinfo(\"[ error ]---出现异常\")\n",
    "#pdf下载\n",
    "\n",
    "def pdf_down():\n",
    "    showinfo(\"[ run ]---正在进行pdf下载\")\n",
    "    showinfo(\"[ tip ]---这一步需要很长时间，请耐心等待。\")\n",
    "    img_dir = \"pdf/\"\n",
    "    thread_num = 50\n",
    "    timeout = 30\n",
    "    len_to_download = 0\n",
    "    if not os.path.exists(img_dir):\n",
    "        os.makedirs(img_dir)\n",
    "    def download(img_url,img_name):\n",
    "        img_name = img_name +\".pdf\"\n",
    "        if os.path.isfile(os.path.join(img_dir,img_name)):\n",
    "            return\n",
    "        with closing(requests.get(img_url,stream=True,headers=headers,timeout=timeout)) as r:\n",
    "            rc = r.status_code\n",
    "            if 299 < rc or rc < 200:\n",
    "                showinfo ('returnCode%s\\t%s' % (rc, img_url))\n",
    "                return\n",
    "            content_length = int(r.headers.get('content-length', '0'))\n",
    "            if content_length == 0:\n",
    "                showinfo ('size0\\t%s' % img_url)\n",
    "                return\n",
    "            try:\n",
    "                with open(os.path.join(img_dir,img_name),\"wb\") as f:\n",
    "                    for data in r.iter_content(8192):\n",
    "                        f.write(data)\n",
    "    #             jpg_name = img_name + \".jpg\"    \n",
    "    #             page = convert_from_path(os.path.join(img_dir,img_name))\n",
    "    #             page[0].save(os.path.join(img_dir,jpg_name),\"PNG\")\n",
    "    #                 image = convert_from_path(os.path.join(img_dir,i))\n",
    "    #                 image[0].save(os.path.join(img_dir,name),\"PNG\")\n",
    "            except:\n",
    "                showinfo('savefail\\t%s' % img_url)\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    def loop(imgs):\n",
    "    #     showinfo ('thread %s is running...' % threading.current_thread().name)\n",
    "        while True:\n",
    "            try:\n",
    "                with lock:\n",
    "                    img_url,img_name = next(imgs)\n",
    "    #                 showinfo(img_name)\n",
    "            except StopIteration:\n",
    "                break\n",
    "            try:\n",
    "                download(img_url,img_name)\n",
    "            except:\n",
    "                global failurls\n",
    "                failurls.append((img_url,img_name))\n",
    "                showinfo(\"exceptfail\\t%s\"%img_url)\n",
    "#         showinfo(\"thread %s is end ...\"% threading.current_thread().name)\n",
    "    def get_img_url_generate():\n",
    "        imgs = []\n",
    "        df = pd.read_excel(\"./cleaned/demo.xlsx\")\n",
    "        global len_to_download\n",
    "        len_to_download = len(df)\n",
    "        df = df[[\"pdf下载链接\",\"专利号\"]]\n",
    "        for i,j in zip(df.pdf下载链接,df.专利号):\n",
    "            imgs = []\n",
    "            img_url = i\n",
    "            img_name = j\n",
    "            imgs.append(img_url)\n",
    "            imgs.append(img_name)\n",
    "            try:\n",
    "                if img_url:\n",
    "                    yield imgs\n",
    "            except:\n",
    "                break\n",
    "    tsk = []\n",
    "    imgs = get_img_url_generate()\n",
    "    for i in range(0,thread_num):\n",
    "        t = threading.Thread(target=loop,name=\"LoopThread %s\" %i,args=(imgs,))\n",
    "        t.start()\n",
    "        tsk.append(t)\n",
    "    for tt in tsk:\n",
    "        tt.join()\n",
    "    showinfo(\"[ run ]---pdf下载完成，正在检查是否有下载失败的内容\")\n",
    "    def tryagain_fail(fail_urls):\n",
    "        global failurls\n",
    "        failurls = []\n",
    "        for img_url, img_name in fail_urls:\n",
    "            img_name = img_name +\".pdf\"\n",
    "            if os.path.isfile(os.path.join(img_dir,img_name)):\n",
    "                return\n",
    "            r = requests.get(img_url,stream=True,headers=headers,timeout=timeout)\n",
    "            rc = r.status_code\n",
    "            if 299 < rc or rc < 200:\n",
    "                showinfo ('returnCode%s\\t%s' % (rc, img_url))\n",
    "                return\n",
    "            content_length = int(r.headers.get('content-length', '0'))\n",
    "            if content_length == 0:\n",
    "                showinfo ('size0\\t%s' % img_url)\n",
    "                return\n",
    "            try:\n",
    "                with open(os.path.join(img_dir,img_name),\"wb\") as f:\n",
    "                    for data in r.iter_content(8192):\n",
    "                        f.write(data)\n",
    "            except:\n",
    "                showinfo('savefail\\t%s' % img_url)\n",
    "                failurls.append((img_url,img_name))\n",
    "    if len(failurls) != 0:\n",
    "        showinfo(\"[ warning ]---有\"+str(len(failurls))+\"个下载失败，现在尝试重下\")\n",
    "        flag = 0\n",
    "        while True:\n",
    "            if len(failurls)==0:\n",
    "                showinfo(\"[ ok ]---全部重下完成\")\n",
    "                break\n",
    "            if len(os.listdir(img_dir)) == len_to_download:\n",
    "                showinfo(\"[ ok ]---全部重下完成\")\n",
    "                break\n",
    "            if flag >= 5:\n",
    "                showinfo(\"[ error ]---以下链接多次下载仍然失败\")\n",
    "                showinfo(\" 可尝试手动下载，放在image文件夹中\")\n",
    "                for i,j in failurls:\n",
    "                    showinfo(i,j)\n",
    "                break\n",
    "            tryagain_fail(failurls)\n",
    "            flag += 1\n",
    "    showinfo(\"[ run ]---开始pdf转png\")\n",
    "    png_dir = \"png/\"\n",
    "    if not os.path.exists(png_dir):\n",
    "        os.makedirs(png_dir)\n",
    "    for j,i in enumerate(os.listdir(img_dir)):\n",
    "        name = i.split(\".\")[0] + \".png\"\n",
    "        if os.path.isfile(os.path.join(png_dir,name)):\n",
    "            continue\n",
    "        try:\n",
    "            image = convert_from_path(os.path.join(img_dir,i))\n",
    "            image[0].save(os.path.join(png_dir,name),\"PNG\")\n",
    "            if j % 50 == 0:\n",
    "                showinfo(\"完成了\"+str(j)+\"个\")\n",
    "        except:\n",
    "            showinfo(\"出错 --\"+name)\n",
    "    files = os.listdir(\"./png/\")\n",
    "    showinfo(\"[ run ]---开始图片切割\")\n",
    "    for j,i in enumerate(files):\n",
    "        img = Image.open(\"./png/\"+i)\n",
    "        w,h = img.size\n",
    "        img_get = img.crop((0,int(h/2),w,h))\n",
    "        tmp = img.crop((3*w/5,0,w,h/7))\n",
    "        if not os.path.exists(\"png_time\"):\n",
    "            os.makedirs(\"png_time\")\n",
    "        if not os.path.exists(\"png_get\"):\n",
    "            os.makedirs(\"png_get\")\n",
    "        tmp.save(\"png_time/\"+i)\n",
    "        img_get.save(\"png_get/\"+i)\n",
    "        if j%50 == 0:\n",
    "            showinfo(\"完成了\"+str(j)+\"个\")\n",
    "    showinfo(\"[ ok ]---pdf转png成功，保存在png_get,png_time文件夹中\")        \n",
    "    \n",
    "    \n",
    "    \n",
    "def png2excel():\n",
    "    showinfo(\"[ run ]---正在进行将图片插入到excel中\")\n",
    "    try:\n",
    "        demo = xlrd.open_workbook(\"./cleaned/demo.xlsx\",on_demand=True)\n",
    "        sheet_names = demo.sheet_names()\n",
    "        final = xlsxwriter.Workbook(\"./cleaned/img.xlsx\")\n",
    "        for sheet_name in sheet_names:\n",
    "            worksheet = final.add_worksheet(sheet_name)\n",
    "            nrows = demo.sheet_by_name(sheet_name).nrows\n",
    "            ncols = demo.sheet_by_name(sheet_name).ncols\n",
    "            i = 0\n",
    "            while i<nrows:\n",
    "                worksheet.write_row(i,0,demo.sheet_by_name(sheet_name).row_values(i))\n",
    "                if i >0:\n",
    "                    s = str(demo.sheet_by_name(sheet_name).cell(i,ncols-2)).replace(\"text:\",\"\").replace(\"'\",\"\")\n",
    "                    png = \"image_get/\"+s+\".png\"\n",
    "                    worksheet.insert_image(i,ncols,png,{'x_scale': 0.09, 'y_scale': 0.09})\n",
    "                    tim = \"image_time/\"+s+\".png\"\n",
    "                    worksheet.insert_image(i,ncols+1,tim,{'x_scale': 0.3, 'y_scale': 0.3})\n",
    "                i += 1\n",
    "            worksheet.write(0,ncols,\"专利图片\")\n",
    "            worksheet.write(0,ncols+1,\"授权时间\")\n",
    "            worksheet.set_default_row(80)\n",
    "            worksheet.set_column(ncols,ncols+1,25)\n",
    "        final.close()\n",
    "        showinfo(\"[ ok ]---插入图片成功，已保存在cleaned文件夹img.xlsx中\")\n",
    "    except:\n",
    "        showinfo(\"[ error ]---出现未知错误\")\n",
    "\n",
    "def vip():\n",
    "    showinfo(\"[ start ]---程序开始自动运行\")\n",
    "    showinfo(\"[ tip ]---请耐心等待\")\n",
    "    time.sleep(2)\n",
    "    spider()\n",
    "    clean()\n",
    "    clean_deep()\n",
    "    pdf_down()\n",
    "    png2excel()\n",
    "    showinfo(\"[ ok ]---一键操作完成\")\n",
    "    \n",
    "fun_frame_Button_spider = Button(fun_frame,text=\"开始爬取数据\",command=spider).grid(row=0,column=2)        \n",
    "fun_frame_Button_clean = Button(fun_frame,text=\"初步数据整理\",command=clean).grid(row=0,column=3)\n",
    "fun_frame_Button_clean_deep = Button(fun_frame,text=\"深度清洗源数据\",command=clean_deep).grid(row=0,column=4)\n",
    "fun_frame_Button_pdf_download = Button(fun_frame,text=\"pdf下载\",command=pdf_down).grid(row=0,column=5)\n",
    "fun_frame_Button_png2excel = Button(fun_frame,text=\"插入图片到excel\",command=png2excel).grid(row=0,column=6)\n",
    "fun_frame_Button_vip = Button(fun_frame,text=\"一键完成爬取清洗下载保存导出\",command=vip,width=100,padx=10,pady=10).grid(row=1,columnspan=7)\n",
    "    \n",
    "\n",
    "key_frame.grid(row=0,column=0)\n",
    "bad_frame.grid(row=0,column=1)\n",
    "fun_frame.grid(row=1,columnspan=2)\n",
    "out_frame.grid(row=2,columnspan=2)\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
