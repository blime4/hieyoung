{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ run ]---开始爬取数据\n",
      "[ tip ]---这一步需要的时间，和爬取的时间间隔和爬取的内容数量有关，请耐心等待。\n",
      "[一切正常]---开始爬取 plant hanger\n",
      "一共127个论文，共3页\n",
      "[一切正常]---爬取到第2页\n",
      "[一切正常]---爬取到第3页\n",
      "[ ok ]---plant hanger\n",
      "[ ok ]---全部导出完毕，保存在raw_data文件夹中\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# import pandas as pd\n",
    "from tkinter import *\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from contextlib import closing\n",
    "import threading\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageEnhance\n",
    "import xlsxwriter\n",
    "import xlrd\n",
    "headers = {\n",
    "    \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36\"\n",
    "}\n",
    "url = \"http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=page_change&u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&r=0&f=S&l=50&TERM1=search_change&FIELD1=&co1=AND&TERM2=&FIELD2=&d=PTXT\"\n",
    "time_sacle = 30\n",
    "print(\"[ run ]---开始爬取数据\")\n",
    "print(\"[ tip ]---这一步需要的时间，和爬取的时间间隔和爬取的内容数量有关，请耐心等待。\")\n",
    "key_words = [\"plant hanger\"]\n",
    "spider_key_words = key_words\n",
    "for key_word in spider_key_words:\n",
    "    page_a = []\n",
    "    page_img = []\n",
    "    page_href = []\n",
    "    key_words_url = url\n",
    "    key_words_url = key_words_url.replace(\"search_change\",str(key_word))\n",
    "    url_1 = key_words_url\n",
    "    url_1 = url_1.replace(\"page_change\",\"1\")\n",
    "    response = requests.get( url_1 , headers=headers )\n",
    "    if response.status_code == 200:\n",
    "        print(\"[一切正常]---开始爬取 \"+key_word)\n",
    "    else:\n",
    "        print(\"[出错]---错误状态码：\"+response.status_code)\n",
    "    html_doc = response.text\n",
    "    response.close()\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    total_len = soup.find(\"body\").find_all(\"i\")[1].find_all(\"strong\")[2].get_text()\n",
    "    page_num = int(float(total_len)/50.5)+2\n",
    "    print(\"一共\"+total_len+\"个论文，共\"+str(page_num-1)+\"页\")\n",
    "    soup_tb = soup.find_all(\"table\")\n",
    "    for tb in soup_tb:\n",
    "        for tr in tb.find_all(\"tr\"):\n",
    "            valign_top = list(tr.find_all(\"td\",attrs={\"valign\":\"top\"}))\n",
    "            if len(valign_top)>=2:\n",
    "                num = valign_top[1].get_text().replace(\",\",\"\")\n",
    "                img = \"https://pdfpiw.uspto.gov/.piw?Docid=\"+str(num)\n",
    "                top = valign_top[2]\n",
    "                href = \"http://patft.uspto.gov/\"+str(top.a.get(\"href\"))\n",
    "                a = top.get_text()\n",
    "                a = a.replace(\"\\n\",\" \")\n",
    "                page_a.append(a)\n",
    "                page_img.append(img)\n",
    "                page_href.append(href)\n",
    "    time.sleep(int(time_sacle))\n",
    "    if page_num >= 2:\n",
    "        for i in range(2,page_num):\n",
    "            url_i = key_words_url\n",
    "            url_i = url_i.replace(\"page_change\",str(i))\n",
    "            response = requests.get( url_i , headers=headers )\n",
    "            if response.status_code == 200:\n",
    "                print(\"[一切正常]---爬取到第\"+str(i)+\"页\")\n",
    "            else:\n",
    "                print(\"[出错]---错误状态码：\"+response.status_code)\n",
    "            html_doc = response.text\n",
    "            response.close()\n",
    "            soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "            soup_tb = soup.find_all(\"table\")\n",
    "            for tb in soup_tb:\n",
    "                for tr in tb.find_all(\"tr\"):\n",
    "                    valign_top = list(tr.find_all(\"td\",attrs={\"valign\":\"top\"}))\n",
    "                    if len(valign_top)>=2:\n",
    "                        num = valign_top[1].get_text().replace(\",\",\"\")\n",
    "                        img = \"https://pdfpiw.uspto.gov/.piw?Docid=\"+str(num)\n",
    "                        top = valign_top[2]\n",
    "                        href = \"http://patft.uspto.gov/\"+str(top.a.get(\"href\"))\n",
    "                        a = top.get_text()\n",
    "                        a = a.replace(\"\\n\",\" \")\n",
    "                        page_a.append(a)\n",
    "                        page_img.append(img)\n",
    "                        page_href.append(href)\n",
    "            time.sleep(int(time_sacle))\n",
    "    page_dict = {\"标题\":page_a,\"专利链接\":page_href,\"图片链接\":page_img}\n",
    "    page_df = pd.DataFrame(page_dict)\n",
    "    if not os.path.exists(\"raw_data\"):\n",
    "        os.mkdir(\"raw_data\")\n",
    "    page_df.to_excel(\"./raw_data/\"+key_word+\".xlsx\",index=None)\n",
    "    print(\"[ ok ]---\"+key_word)\n",
    "print(\"[ ok ]---全部导出完毕，保存在raw_data文件夹中\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
